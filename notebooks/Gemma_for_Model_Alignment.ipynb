{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4TinoiDCCibN"
      },
      "source": [
        "##### Copyright 2024 Google LLC."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "lxzsE00VCqH6"
      },
      "outputs": [],
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WD8i4bJBJQ_5"
      },
      "source": [
        "# Model Alignment of Gemma"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VM2hRK9yua-_"
      },
      "source": [
        "Model alignment is the process of automatically updating a prompt based on developer-provided feedback.\n",
        "\n",
        "This notebook shows how the [Model Alignment Python API](https://github.com/PAIR-code/model-alignment) can be used with Gemma and Gemini models to modify non-agentic prompts (e.g. ideation, extraction, summarization, etc. that don\u0027t make use of tools or external knowledge databases) based on  feedback through two different approaches described below.\n",
        "\n",
        "Running this notebook requires a [GPU-backed Colab runtime][colab_accelerators], such as a T4, L4, or A100, which may require a paid [subscription][colab_subscriptions].\n",
        "\n",
        "With model alignment, there are two roles that models take as part of the process, although these can be the same model in practice:\n",
        "\n",
        "1. **Target model**: The model that the target prompt will be run with. The alignment process is meant to make the prompt work well with the target model, as determined by you.\n",
        "  \n",
        "  - This notebook uses the Gemma2 2B Instruction-Tuned model, loaded by Keras from weights hosted on Kaggle as the target model. Loading Gemma for this Colab requires:\n",
        "\n",
        "    1. [Authenticating][kagglehub_auth] with a Kaggle account that has accepted the Gemma license agreement; and\n",
        "    1. A [GPU-backed runtime][colab_accelerators], such as a T4, L4, or A100, which may require a paid [subscription][colab_subscriptions].\n",
        "\n",
        "[colab_accelerators]: https://research.google.com/colaboratory/faq.html#gpu-availability\n",
        "[colab_subscriptions]: https://colab.research.google.com/signup\n",
        "[kagglehub_auth]: https://github.com/Kaggle/kagglehub#authenticate\n",
        "[kaggle_gemma]: https://www.kaggle.com/models/keras/gemma\n",
        "  \n",
        "2. **Alignment model**: The model that will be used to perform the alignment steps. This model is used in the steps that perform alignment steps such as creating principles and updating the target prompt.\n",
        "\n",
        "  - This notebook uses the Gemini Pro 1.5 model run through Google\u0027s Developer API as the alignment model. This requires you to provide an [API key](https://aistudio.google.com/app/apikey). The Gemini model is larger in size than the Gemma model, which makes it better at the alignment tasks shown in this notebook. A Gemma model larger than 2B would also suffice for the alignment of the prompts.\n",
        "\n",
        "Alignment can be performed through two different methods, both of which are shown in this notebook:\n",
        "\n",
        "1. Prompts are modified through guidlines (also called principles) which are curated by critiquing or rewriting of model responses.\n",
